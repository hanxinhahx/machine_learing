{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-29T09:17:48.002275Z",
     "start_time": "2025-11-29T09:17:43.827099Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sympy.physics.units import momentum\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "# 解决负号'-'显示为方块的问题\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 配置全局参数",
   "id": "acc7a111e9e2190a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T09:17:48.255532Z",
     "start_time": "2025-11-29T09:17:48.224425Z"
    }
   },
   "cell_type": "code",
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # 自动适配CPU/GPU\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 30  # 论文训练轮次（20-30轮足够收敛）\n",
    "LEARNING_RATE = 0.01  # 论文推荐学习率"
   ],
   "id": "2c6309863605758d",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 数据预处理",
   "id": "ca3029d6dd90cb8c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T09:17:48.286981Z",
     "start_time": "2025-11-29T09:17:48.271974Z"
    }
   },
   "cell_type": "code",
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),  # MNIST原始28×28，论文输入32×32\n",
    "    transforms.ToTensor(),  # 转为Tensor：shape=(1,32,32)，值范围[0,1]\n",
    "    transforms.Normalize((0.1307,), (0.3081,))  # MNIST数据集统计均值/方差，提升训练稳定性\n",
    "])"
   ],
   "id": "106c7b00e0c357c2",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 加载MINST数据集",
   "id": "439913c1422ef3cb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T09:17:48.380490Z",
     "start_time": "2025-11-29T09:17:48.303974Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = datasets.MNIST(\n",
    "    root='./data', train=True, download=True, transform=transform\n",
    ")\n",
    "test_dataset = datasets.MNIST(\n",
    "    root='./data', train=False, download=True, transform=transform\n",
    ")"
   ],
   "id": "f1b3e23a763249df",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 构建数据加载器",
   "id": "15a5a56e7177dddd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T09:17:48.412491Z",
     "start_time": "2025-11-29T09:17:48.397483Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_loader=DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader=DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False) # 测试集不用进行打乱操作"
   ],
   "id": "45504cd9e4398d43",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Le-Net5初始结构",
   "id": "75e5e3f927bc28c8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T09:17:48.444487Z",
     "start_time": "2025-11-29T09:17:48.429484Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        # 特征提取部分（卷积+池化）\n",
    "        self.features = nn.Sequential(\n",
    "            # C1层：6个5×5卷积核，步长1，无Padding → 输出(6,28,28)\n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=0),\n",
    "            nn.Sigmoid(),  # 论文原版激活函数（非ReLU）\n",
    "            # S2层：2×2平均池化，步长2 → 输出(6,14,14)\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # C3层：16个5×5卷积核，步长1，无Padding → 输出(16,10,10)\n",
    "            # 论文中C3为「部分连接」，此处简化为全连接（性能一致，代码更简洁）\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0),\n",
    "            nn.Sigmoid(),\n",
    "            # S4层：2×2平均池化，步长2 → 输出(16,5,5)\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        # 分类部分（全连接层）\n",
    "        self.classifier = nn.Sequential(\n",
    "            # F5层：16×5×5=400 → 120维\n",
    "            nn.Linear(in_features=16*5*5, out_features=120),\n",
    "            nn.Sigmoid(),\n",
    "            # F6层：120 → 84维（论文中对应7×12编码）\n",
    "            nn.Linear(in_features=120, out_features=84),\n",
    "            nn.Sigmoid(),\n",
    "            # 输出层：84 → 10维（0-9数字，替代论文RBF层）\n",
    "            nn.Linear(in_features=84, out_features=10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 前向传播：输入 → 特征提取 → 展平 → 分类\n",
    "        x = self.features(x)\n",
    "        x = x.view(-1, 16*5*5)  # 展平：(batch_size, 16*5*5)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ],
   "id": "a509e0f5b7eef0de",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 初始化模型并转移到CUDA上",
   "id": "97fe3b0e770e101d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T09:17:48.555024Z",
     "start_time": "2025-11-29T09:17:48.460998Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = LeNet5().to(DEVICE)\n",
    "print(model)"
   ],
   "id": "9caa1a87261e606f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet5(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): Sigmoid()\n",
      "    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (4): Sigmoid()\n",
      "    (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=400, out_features=120, bias=True)\n",
      "    (1): Sigmoid()\n",
      "    (2): Linear(in_features=120, out_features=84, bias=True)\n",
      "    (3): Sigmoid()\n",
      "    (4): Linear(in_features=84, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 配置训练组件",
   "id": "d0e10c70614ea2f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T09:17:48.585718Z",
     "start_time": "2025-11-29T09:17:48.571019Z"
    }
   },
   "cell_type": "code",
   "source": [
    "criterion = nn.CrossEntropyLoss() # 交叉熵损失函数\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE,momentum=0.9) # 优化器：SGD+动量"
   ],
   "id": "8811c2e210a5431a",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-11-29T09:17:48.602712Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 记录训练历史（用于后续可视化）\n",
    "train_loss_history = []\n",
    "train_acc_history = []\n",
    "val_loss_history = []\n",
    "val_acc_history = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # 训练阶段\n",
    "    model.train()  # 开启训练模式（影响Dropout等层，此处无但规范）\n",
    "    train_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "        # 数据移至设备\n",
    "        data, targets = data.to(DEVICE), targets.to(DEVICE)\n",
    "\n",
    "        # 前向传播\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # 反向传播+参数更新\n",
    "        optimizer.zero_grad()  # 清空梯度\n",
    "        loss.backward()  # 计算梯度\n",
    "        optimizer.step()  # 更新参数\n",
    "\n",
    "        # 统计训练损失和准确率\n",
    "        train_loss += loss.item() * data.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_train += targets.size(0)\n",
    "        correct_train += (predicted == targets).sum().item()\n",
    "\n",
    "    # 计算训练集平均损失和准确率\n",
    "    avg_train_loss = train_loss / total_train\n",
    "    train_acc = correct_train / total_train\n",
    "    train_loss_history.append(avg_train_loss)\n",
    "    train_acc_history.append(train_acc)\n",
    "\n",
    "    # 验证阶段\n",
    "    model.eval()  # 开启评估模式\n",
    "    val_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "\n",
    "    with torch.no_grad():  # 禁用梯度计算，节省内存\n",
    "        for data, targets in test_loader:\n",
    "            data, targets = data.to(DEVICE), targets.to(DEVICE)\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            # 统计验证损失和准确率\n",
    "            val_loss += loss.item() * data.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_val += targets.size(0)\n",
    "            correct_val += (predicted == targets).sum().item()\n",
    "\n",
    "    # 计算验证集平均损失和准确率\n",
    "    avg_val_loss = val_loss / total_val\n",
    "    val_acc = correct_val / total_val\n",
    "    val_loss_history.append(avg_val_loss)\n",
    "    val_acc_history.append(val_acc)\n",
    "\n",
    "    # 打印每轮训练结果\n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}], \"\n",
    "          f\"Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.4f}, \"\n",
    "          f\"Val Loss: {avg_val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "# -------------------------- 6. 模型评估与可视化 --------------------------\n",
    "# 1. 最终测试集评估\n",
    "model.eval()\n",
    "final_correct = 0\n",
    "final_total = 0\n",
    "with torch.no_grad():\n",
    "    for data, targets in test_loader:\n",
    "        data, targets = data.to(DEVICE), targets.to(DEVICE)\n",
    "        outputs = model(data)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        final_total += targets.size(0)\n",
    "        final_correct += (predicted == targets).sum().item()\n",
    "\n",
    "print(f\"\\n最终测试集准确率：{final_correct/final_total:.4f}\")\n",
    "print(f\"最终测试集错误率：{(1 - final_correct/final_total)*100:.2f}%\")\n",
    "\n",
    "# 2. 训练历史可视化（准确率+损失）\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# 准确率曲线\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, EPOCHS+1), train_acc_history, label='训练准确率')\n",
    "plt.plot(range(1, EPOCHS+1), val_acc_history, label='验证准确率')\n",
    "plt.title('LeNet-5 准确率变化')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 损失曲线\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, EPOCHS+1), train_loss_history, label='训练损失')\n",
    "plt.plot(range(1, EPOCHS+1), val_loss_history, label='验证损失')\n",
    "plt.title('LeNet-5 损失变化')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3. 预测示例（随机展示5张测试图）\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # 随机选5个测试样本\n",
    "    random_indices = np.random.choice(len(test_dataset), 5)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    for i, idx in enumerate(random_indices):\n",
    "        data, target = test_dataset[idx]\n",
    "        data = data.unsqueeze(0).to(DEVICE)  # 扩展为batch维度\n",
    "        output = model(data)\n",
    "        predicted = torch.argmax(output).item()\n",
    "\n",
    "        # 绘制图像\n",
    "        plt.subplot(1, 5, i+1)\n",
    "        plt.imshow(data.squeeze().cpu().numpy(), cmap='gray')\n",
    "        plt.title(f\"预测：{predicted}\\n真实：{target}\")\n",
    "        plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "5e6892c5b076ec81",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Train Loss: 2.3082, Train Acc: 0.1058, Val Loss: 2.3088, Val Acc: 0.0974\n",
      "Epoch [2/30], Train Loss: 2.3068, Train Acc: 0.1051, Val Loss: 2.3052, Val Acc: 0.1010\n",
      "Epoch [3/30], Train Loss: 2.3048, Train Acc: 0.1066, Val Loss: 2.3080, Val Acc: 0.1135\n",
      "Epoch [4/30], Train Loss: 2.3040, Train Acc: 0.1085, Val Loss: 2.3054, Val Acc: 0.0982\n",
      "Epoch [5/30], Train Loss: 2.3025, Train Acc: 0.1080, Val Loss: 2.3014, Val Acc: 0.1032\n",
      "Epoch [6/30], Train Loss: 2.2981, Train Acc: 0.1204, Val Loss: 2.2876, Val Acc: 0.1009\n",
      "Epoch [7/30], Train Loss: 1.9118, Train Acc: 0.3695, Val Loss: 1.0598, Val Acc: 0.6625\n",
      "Epoch [8/30], Train Loss: 0.8013, Train Acc: 0.7382, Val Loss: 0.6083, Val Acc: 0.8181\n",
      "Epoch [9/30], Train Loss: 0.5002, Train Acc: 0.8552, Val Loss: 0.3871, Val Acc: 0.8862\n",
      "Epoch [10/30], Train Loss: 0.3511, Train Acc: 0.8981, Val Loss: 0.2983, Val Acc: 0.9118\n",
      "Epoch [11/30], Train Loss: 0.2833, Train Acc: 0.9167, Val Loss: 0.2387, Val Acc: 0.9296\n",
      "Epoch [12/30], Train Loss: 0.2390, Train Acc: 0.9293, Val Loss: 0.2154, Val Acc: 0.9364\n",
      "Epoch [13/30], Train Loss: 0.2053, Train Acc: 0.9394, Val Loss: 0.1777, Val Acc: 0.9476\n",
      "Epoch [14/30], Train Loss: 0.1798, Train Acc: 0.9460, Val Loss: 0.1549, Val Acc: 0.9521\n",
      "Epoch [15/30], Train Loss: 0.1586, Train Acc: 0.9531, Val Loss: 0.1360, Val Acc: 0.9580\n",
      "Epoch [16/30], Train Loss: 0.1426, Train Acc: 0.9572, Val Loss: 0.1207, Val Acc: 0.9631\n",
      "Epoch [17/30], Train Loss: 0.1287, Train Acc: 0.9621, Val Loss: 0.1138, Val Acc: 0.9645\n",
      "Epoch [18/30], Train Loss: 0.1185, Train Acc: 0.9648, Val Loss: 0.1024, Val Acc: 0.9701\n",
      "Epoch [19/30], Train Loss: 0.1091, Train Acc: 0.9677, Val Loss: 0.0937, Val Acc: 0.9707\n",
      "Epoch [20/30], Train Loss: 0.1009, Train Acc: 0.9701, Val Loss: 0.0881, Val Acc: 0.9727\n",
      "Epoch [21/30], Train Loss: 0.0949, Train Acc: 0.9717, Val Loss: 0.0903, Val Acc: 0.9721\n",
      "Epoch [22/30], Train Loss: 0.0897, Train Acc: 0.9731, Val Loss: 0.0767, Val Acc: 0.9767\n",
      "Epoch [23/30], Train Loss: 0.0840, Train Acc: 0.9750, Val Loss: 0.0729, Val Acc: 0.9785\n",
      "Epoch [24/30], Train Loss: 0.0797, Train Acc: 0.9768, Val Loss: 0.0686, Val Acc: 0.9793\n",
      "Epoch [25/30], Train Loss: 0.0761, Train Acc: 0.9770, Val Loss: 0.0684, Val Acc: 0.9797\n",
      "Epoch [26/30], Train Loss: 0.0717, Train Acc: 0.9785, Val Loss: 0.0651, Val Acc: 0.9796\n",
      "Epoch [27/30], Train Loss: 0.0688, Train Acc: 0.9799, Val Loss: 0.0634, Val Acc: 0.9805\n",
      "Epoch [28/30], Train Loss: 0.0662, Train Acc: 0.9809, Val Loss: 0.0582, Val Acc: 0.9826\n",
      "Epoch [29/30], Train Loss: 0.0640, Train Acc: 0.9810, Val Loss: 0.0559, Val Acc: 0.9831\n",
      "Epoch [30/30], Train Loss: 0.0619, Train Acc: 0.9814, Val Loss: 0.0581, Val Acc: 0.9815\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "e14cc48b72ab99ed",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
